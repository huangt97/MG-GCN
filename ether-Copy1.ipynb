{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "from train_ether import Train_Model_Ether\n",
    "#from tqdm import tqdm, trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "from model import *\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argument():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'ether'\n",
    "        self.gamma = 1\n",
    "        self.hidden = 128\n",
    "        self.time = 3\n",
    "        self.save_path_acc = \"./best_ether/acc/\"\n",
    "        self.save_path_loss = \"./best_ether/loss/\"\n",
    "        self.save_path_both = \"./best_ether/both/\"\n",
    "        self.patience = 30\n",
    "        self.batch_size = 256\n",
    "        self.epochs = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.weight_decay = 0\n",
    "        self.num_labels = 41\n",
    "        self.feature_dim = 602\n",
    "        self.walk_times = 10\n",
    "        self.eva_times = 1\n",
    "        self.seed = 2019\n",
    "        self.dropout = 0\n",
    "        self.way = 'both'\n",
    "        self.conbime = 'Lstm'\n",
    "        self.do_walk = True\n",
    "args = argument()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different walk time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c09318bf6841f199b200f98b891a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different seed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa9a6a7376453cb83be94b814f370a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index 572\n",
      "val_index 82\n",
      "test_index 162\n",
      "adj torch.Size([1402220, 1402220])\n",
      "features torch.Size([1402220, 12])\n",
      "train walk\n",
      "valid walk\n",
      "cuda ready\n",
      "\n",
      "Training started.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65374015935e47fa8f57414625c2b53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 7.455941200256348\n",
      "epoch_loss 13.2516450881958\n",
      "epoch_loss 18.731905460357666\n",
      "loss_node tensor(3.7583, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(19, device='cuda:0') label_predict: tensor([5, 4, 5, 4, 5, 4, 0, 3, 0, 4, 0, 3, 0, 4, 0, 0, 4, 3, 4, 3, 4, 4, 4, 5,\n",
      "        4, 5, 0, 2, 4, 0, 5, 0, 3, 5, 5, 3, 4, 3, 5, 3, 5, 4, 4, 5, 4, 3, 0, 0,\n",
      "        5, 4, 4, 4, 3, 3, 0, 4, 3, 3, 0, 5, 0, 4, 5, 3, 3, 3, 0, 4, 5, 4, 0, 3,\n",
      "        3, 0, 4, 5, 4, 0, 5, 4, 4, 0], device='cuda:0')\n",
      "epoch 0 loss_train: 32.7481 acc_train: 0.2028 || loss_valid: 45.8324 acc_valid: 0.2317\n",
      "epoch_loss 5.2497148513793945\n",
      "epoch_loss 9.434021472930908\n",
      "epoch_loss 12.980613946914673\n",
      "loss_node tensor(2.8664, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(23, device='cuda:0') label_predict: tensor([5, 1, 5, 5, 5, 4, 0, 5, 0, 4, 0, 3, 0, 4, 0, 0, 4, 5, 4, 3, 5, 4, 4, 5,\n",
      "        4, 5, 0, 2, 0, 0, 5, 0, 0, 5, 5, 5, 3, 3, 5, 3, 5, 4, 5, 5, 4, 5, 0, 0,\n",
      "        5, 4, 4, 5, 0, 5, 0, 4, 3, 5, 0, 5, 0, 5, 5, 3, 3, 5, 0, 0, 5, 5, 0, 5,\n",
      "        3, 0, 5, 5, 5, 0, 5, 5, 4, 0], device='cuda:0')\n",
      "epoch 1 loss_train: 22.6934 acc_train: 0.2605 || loss_valid: 34.9557 acc_valid: 0.2805\n",
      "epoch_loss 3.7367496490478516\n",
      "epoch_loss 6.965141773223877\n",
      "epoch_loss 9.215331315994263\n",
      "loss_node tensor(2.1912, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(28, device='cuda:0') label_predict: tensor([5, 1, 5, 5, 5, 1, 0, 5, 0, 1, 0, 0, 0, 4, 0, 0, 4, 5, 4, 3, 5, 4, 4, 5,\n",
      "        4, 5, 0, 2, 1, 0, 5, 0, 0, 5, 5, 5, 0, 3, 5, 3, 5, 4, 5, 5, 0, 5, 0, 3,\n",
      "        5, 1, 4, 5, 0, 5, 0, 0, 3, 5, 0, 5, 0, 5, 5, 3, 1, 5, 0, 0, 5, 5, 0, 5,\n",
      "        3, 1, 5, 5, 5, 0, 5, 1, 0, 0], device='cuda:0')\n",
      "epoch 2 loss_train: 16.1107 acc_train: 0.3129 || loss_valid: 26.7219 acc_valid: 0.3415\n",
      "epoch_loss 2.77066969871521\n",
      "epoch_loss 5.410995244979858\n",
      "epoch_loss 7.1900399923324585\n",
      "loss_node tensor(1.8537, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(34, device='cuda:0') label_predict: tensor([5, 1, 5, 0, 5, 1, 0, 5, 0, 1, 0, 0, 1, 1, 0, 0, 4, 0, 1, 1, 5, 1, 1, 5,\n",
      "        1, 5, 0, 1, 1, 1, 5, 0, 0, 5, 5, 5, 0, 3, 5, 1, 5, 1, 1, 5, 0, 5, 0, 3,\n",
      "        5, 1, 1, 5, 1, 5, 1, 0, 3, 1, 1, 5, 0, 0, 5, 1, 1, 5, 0, 0, 1, 5, 1, 5,\n",
      "        1, 1, 5, 5, 5, 0, 5, 1, 0, 0], device='cuda:0')\n",
      "epoch 3 loss_train: 12.57 acc_train: 0.4231 || loss_valid: 22.6062 acc_valid: 0.4146\n",
      "epoch_loss 2.2678778171539307\n",
      "epoch_loss 4.608725309371948\n",
      "epoch_loss 6.245480895042419\n",
      "loss_node tensor(1.7495, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(40, device='cuda:0') label_predict: tensor([5, 1, 5, 0, 5, 1, 1, 5, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 5, 1, 1, 5,\n",
      "        1, 5, 0, 1, 1, 1, 5, 0, 0, 5, 5, 5, 0, 3, 5, 1, 5, 1, 1, 5, 0, 5, 0, 3,\n",
      "        5, 1, 1, 5, 1, 5, 1, 0, 3, 1, 1, 5, 0, 0, 5, 1, 1, 5, 1, 1, 1, 0, 1, 5,\n",
      "        1, 1, 0, 5, 0, 1, 5, 1, 0, 0], device='cuda:0')\n",
      "epoch 4 loss_train: 10.9187 acc_train: 0.5105 || loss_valid: 21.3357 acc_valid: 0.4878\n",
      "epoch_loss 1.974430799484253\n",
      "epoch_loss 4.0136024951934814\n",
      "epoch_loss 5.438485622406006\n",
      "loss_node tensor(1.6228, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(44, device='cuda:0') label_predict: tensor([5, 1, 5, 0, 5, 1, 1, 5, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 5,\n",
      "        1, 5, 0, 1, 1, 1, 5, 1, 3, 5, 5, 5, 0, 3, 5, 1, 5, 1, 1, 5, 0, 3, 0, 3,\n",
      "        5, 1, 1, 0, 1, 5, 1, 0, 3, 1, 1, 5, 0, 0, 5, 1, 1, 0, 1, 0, 1, 0, 1, 5,\n",
      "        1, 1, 0, 5, 0, 1, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 5 loss_train: 9.5078 acc_train: 0.5385 || loss_valid: 19.7899 acc_valid: 0.5366\n",
      "epoch_loss 1.7147901058197021\n",
      "epoch_loss 3.474255084991455\n",
      "epoch_loss 4.627212762832642\n",
      "loss_node tensor(1.4934, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(44, device='cuda:0') label_predict: tensor([5, 1, 5, 0, 5, 1, 1, 5, 1, 1, 0, 0, 1, 1, 1, 0, 4, 0, 1, 1, 0, 1, 1, 5,\n",
      "        1, 5, 0, 1, 1, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 1, 1, 5, 0, 3, 3, 3,\n",
      "        5, 1, 1, 0, 1, 5, 1, 0, 3, 3, 1, 5, 3, 0, 5, 1, 1, 0, 1, 0, 5, 0, 1, 5,\n",
      "        1, 1, 0, 5, 0, 1, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 6 loss_train: 8.0895 acc_train: 0.5717 || loss_valid: 18.2116 acc_valid: 0.5366\n",
      "epoch_loss 1.4776724576950073\n",
      "epoch_loss 3.013631224632263\n",
      "epoch_loss 3.989606022834778\n",
      "loss_node tensor(1.3853, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(45, device='cuda:0') label_predict: tensor([5, 1, 5, 0, 5, 1, 1, 5, 1, 1, 0, 3, 1, 3, 1, 0, 4, 0, 4, 1, 5, 1, 4, 5,\n",
      "        4, 5, 0, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 3, 3,\n",
      "        5, 1, 4, 5, 1, 5, 1, 0, 3, 3, 1, 5, 3, 0, 5, 1, 1, 5, 1, 0, 5, 0, 1, 5,\n",
      "        1, 1, 0, 5, 0, 1, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 7 loss_train: 6.9748 acc_train: 0.5804 || loss_valid: 16.8943 acc_valid: 0.5488\n",
      "epoch_loss 1.2863136529922485\n",
      "epoch_loss 2.689708113670349\n",
      "epoch_loss 3.5918088555336\n",
      "loss_node tensor(1.3061, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(48, device='cuda:0') label_predict: tensor([5, 4, 5, 0, 5, 4, 1, 5, 3, 1, 0, 3, 1, 3, 1, 0, 4, 0, 4, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 3, 3,\n",
      "        5, 1, 4, 5, 1, 5, 1, 0, 3, 5, 1, 5, 3, 0, 5, 1, 4, 5, 1, 0, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 1, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 8 loss_train: 6.2794 acc_train: 0.6066 || loss_valid: 15.9277 acc_valid: 0.5854\n",
      "epoch_loss 1.1446611881256104\n",
      "epoch_loss 2.425239086151123\n",
      "epoch_loss 3.279489278793335\n",
      "loss_node tensor(1.2479, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(48, device='cuda:0') label_predict: tensor([5, 4, 5, 0, 5, 4, 1, 5, 3, 1, 0, 3, 1, 3, 1, 0, 4, 0, 5, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 5, 3, 3,\n",
      "        5, 1, 4, 5, 1, 5, 1, 0, 3, 5, 1, 5, 3, 0, 5, 1, 4, 5, 1, 0, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 1, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 9 loss_train: 5.7334 acc_train: 0.6276 || loss_valid: 15.2186 acc_valid: 0.5854\n",
      "epoch_loss 1.0125938653945923\n",
      "epoch_loss 2.1603901386260986\n",
      "epoch_loss 2.9476569294929504\n",
      "loss_node tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(51, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 4, 1, 5, 3, 4, 0, 0, 1, 3, 1, 0, 4, 0, 5, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 5, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 5, 1, 5, 3, 0, 5, 1, 4, 5, 1, 0, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 3], device='cuda:0')\n",
      "epoch 10 loss_train: 5.1532 acc_train: 0.6608 || loss_valid: 14.613 acc_valid: 0.622\n",
      "epoch_loss 0.9159743189811707\n",
      "epoch_loss 1.9405563473701477\n",
      "epoch_loss 2.6695932745933533\n",
      "loss_node tensor(1.1547, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(52, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 4, 1, 5, 3, 1, 0, 0, 1, 3, 1, 0, 5, 0, 5, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 5, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 5, 1, 5, 3, 0, 5, 1, 4, 5, 1, 0, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 11 loss_train: 4.6671 acc_train: 0.6958 || loss_valid: 14.0819 acc_valid: 0.6341\n",
      "epoch_loss 0.8538594841957092\n",
      "epoch_loss 1.7660688161849976\n",
      "epoch_loss 2.4491868019104004\n",
      "loss_node tensor(1.1098, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(55, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 3, 1, 0, 5, 0, 5, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 5, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 5, 1, 5, 5, 0, 5, 1, 4, 5, 1, 0, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 12 loss_train: 4.2818 acc_train: 0.7185 || loss_valid: 13.5346 acc_valid: 0.6707\n",
      "epoch_loss 0.8095344305038452\n",
      "epoch_loss 1.6545408368110657\n",
      "epoch_loss 2.3000711798667908\n",
      "loss_node tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(56, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 3, 1, 0, 5, 0, 5, 1, 5, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 5, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 13 loss_train: 4.0211 acc_train: 0.743 || loss_valid: 12.9392 acc_valid: 0.6829\n",
      "epoch_loss 0.7728883624076843\n",
      "epoch_loss 1.5548546314239502\n",
      "epoch_loss 2.172878086566925\n",
      "loss_node tensor(1.0163, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(58, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 3, 4, 5,\n",
      "        4, 5, 3, 1, 3, 1, 5, 3, 3, 5, 5, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 0, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        1, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 14 loss_train: 3.7987 acc_train: 0.757 || loss_valid: 12.3935 acc_valid: 0.7073\n",
      "epoch_loss 0.7441475987434387\n",
      "epoch_loss 1.4688681364059448\n",
      "epoch_loss 2.069317638874054\n",
      "loss_node tensor(0.9778, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(63, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 5, 4, 5,\n",
      "        4, 5, 3, 1, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 0, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 15 loss_train: 3.6177 acc_train: 0.7832 || loss_valid: 11.924 acc_valid: 0.7683\n",
      "epoch_loss 0.7236863374710083\n",
      "epoch_loss 1.403271198272705\n",
      "epoch_loss 1.9870980978012085\n",
      "loss_node tensor(0.9462, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 5, 4, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 16 loss_train: 3.4739 acc_train: 0.8042 || loss_valid: 11.5388 acc_valid: 0.7439\n",
      "epoch_loss 0.7039134502410889\n",
      "epoch_loss 1.359850525856018\n",
      "epoch_loss 1.9236054420471191\n",
      "loss_node tensor(0.9238, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 5, 4, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 5, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 17 loss_train: 3.3629 acc_train: 0.8234 || loss_valid: 11.2656 acc_valid: 0.7439\n",
      "epoch_loss 0.6827629804611206\n",
      "epoch_loss 1.3218015432357788\n",
      "epoch_loss 1.8682823777198792\n",
      "loss_node tensor(0.9104, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(58, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 5, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 4, 5, 5, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 18 loss_train: 3.2662 acc_train: 0.8164 || loss_valid: 11.1025 acc_valid: 0.7073\n",
      "epoch_loss 0.6657989025115967\n",
      "epoch_loss 1.2930768728256226\n",
      "epoch_loss 1.8271573781967163\n",
      "loss_node tensor(0.9001, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(59, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 5, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 1, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 4, 5, 0, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 19 loss_train: 3.1943 acc_train: 0.8182 || loss_valid: 10.9774 acc_valid: 0.7195\n",
      "epoch_loss 0.652302086353302\n",
      "epoch_loss 1.2678444385528564\n",
      "epoch_loss 1.790610134601593\n",
      "loss_node tensor(0.8887, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(59, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 5, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 0, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 1, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 20 loss_train: 3.1304 acc_train: 0.8164 || loss_valid: 10.838 acc_valid: 0.7195\n",
      "epoch_loss 0.6394026875495911\n",
      "epoch_loss 1.2407176494598389\n",
      "epoch_loss 1.752062201499939\n",
      "loss_node tensor(0.8785, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(60, device='cuda:0') label_predict: tensor([5, 5, 5, 0, 5, 3, 1, 5, 5, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 4, 5, 5, 0, 3, 5, 3,\n",
      "        5, 1, 5, 0, 1, 5, 1, 0, 5, 3, 1, 5, 5, 0, 5, 1, 4, 5, 1, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 21 loss_train: 3.063 acc_train: 0.8217 || loss_valid: 10.7132 acc_valid: 0.7317\n",
      "epoch_loss 0.6274890303611755\n",
      "epoch_loss 1.214731752872467\n",
      "epoch_loss 1.7152128219604492\n",
      "loss_node tensor(0.8723, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(60, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 0, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 22 loss_train: 2.9986 acc_train: 0.8287 || loss_valid: 10.6384 acc_valid: 0.7317\n",
      "epoch_loss 0.6172207593917847\n",
      "epoch_loss 1.1933056116104126\n",
      "epoch_loss 1.683133989572525\n",
      "loss_node tensor(0.8705, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        4, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 23 loss_train: 2.9425 acc_train: 0.8374 || loss_valid: 10.6156 acc_valid: 0.7439\n",
      "epoch_loss 0.6072577834129333\n",
      "epoch_loss 1.1743190288543701\n",
      "epoch_loss 1.6527551710605621\n",
      "loss_node tensor(0.8705, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(62, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 24 loss_train: 2.8894 acc_train: 0.8409 || loss_valid: 10.6161 acc_valid: 0.7561\n",
      "epoch_loss 0.5972774624824524\n",
      "epoch_loss 1.1564807891845703\n",
      "epoch_loss 1.6238304674625397\n",
      "loss_node tensor(0.8702, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(62, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 1, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 25 loss_train: 2.8389 acc_train: 0.8409 || loss_valid: 10.6126 acc_valid: 0.7561\n",
      "epoch_loss 0.5878057479858398\n",
      "epoch_loss 1.139635145664215\n",
      "epoch_loss 1.597153902053833\n",
      "loss_node tensor(0.8681, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 26 loss_train: 2.7922 acc_train: 0.8462 || loss_valid: 10.587 acc_valid: 0.7439\n",
      "epoch_loss 0.578815758228302\n",
      "epoch_loss 1.1230496764183044\n",
      "epoch_loss 1.57205131649971\n",
      "loss_node tensor(0.8639, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(62, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 4, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 27 loss_train: 2.7483 acc_train: 0.8531 || loss_valid: 10.5349 acc_valid: 0.7561\n",
      "epoch_loss 0.5701254606246948\n",
      "epoch_loss 1.1063600778579712\n",
      "epoch_loss 1.5475102365016937\n",
      "loss_node tensor(0.8593, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(62, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 4, 5, 1, 5, 5, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 28 loss_train: 2.7054 acc_train: 0.8531 || loss_valid: 10.4794 acc_valid: 0.7561\n",
      "epoch_loss 0.5619306564331055\n",
      "epoch_loss 1.090532124042511\n",
      "epoch_loss 1.5236895382404327\n",
      "loss_node tensor(0.8562, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 4, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 29 loss_train: 2.6638 acc_train: 0.8531 || loss_valid: 10.441 acc_valid: 0.7439\n",
      "epoch_loss 0.5541675686836243\n",
      "epoch_loss 1.0757075548171997\n",
      "epoch_loss 1.5008325576782227\n",
      "loss_node tensor(0.8539, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 3,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 4, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 30 loss_train: 2.6238 acc_train: 0.8531 || loss_valid: 10.4134 acc_valid: 0.7439\n",
      "epoch_loss 0.5465899705886841\n",
      "epoch_loss 1.0618091225624084\n",
      "epoch_loss 1.478798896074295\n",
      "loss_node tensor(0.8519, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 1,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 31 loss_train: 2.5853 acc_train: 0.8531 || loss_valid: 10.3895 acc_valid: 0.7439\n",
      "epoch_loss 0.539226770401001\n",
      "epoch_loss 1.0484448075294495\n",
      "epoch_loss 1.4575530886650085\n",
      "loss_node tensor(0.8495, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 1,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 32 loss_train: 2.5482 acc_train: 0.8549 || loss_valid: 10.3596 acc_valid: 0.7439\n",
      "epoch_loss 0.5321730971336365\n",
      "epoch_loss 1.03528892993927\n",
      "epoch_loss 1.4370623230934143\n",
      "loss_node tensor(0.8463, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 1,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 33 loss_train: 2.5123 acc_train: 0.8566 || loss_valid: 10.3209 acc_valid: 0.7439\n",
      "epoch_loss 0.5254426002502441\n",
      "epoch_loss 1.022262692451477\n",
      "epoch_loss 1.4171916246414185\n",
      "loss_node tensor(0.8431, device='cuda:0', grad_fn=<NllLossBackward>) acc: tensor(61, device='cuda:0') label_predict: tensor([4, 5, 5, 0, 5, 3, 1, 5, 3, 1, 0, 3, 1, 5, 1, 3, 5, 0, 5, 4, 0, 5, 5, 5,\n",
      "        1, 5, 3, 4, 5, 1, 5, 3, 3, 5, 3, 5, 0, 3, 5, 4, 5, 1, 5, 5, 0, 3, 5, 1,\n",
      "        0, 1, 5, 0, 1, 5, 1, 0, 5, 3, 2, 5, 5, 0, 5, 1, 1, 5, 3, 5, 1, 0, 1, 5,\n",
      "        4, 1, 0, 5, 0, 3, 5, 1, 0, 1], device='cuda:0')\n",
      "epoch 34 loss_train: 2.4776 acc_train: 0.8601 || loss_valid: 10.2821 acc_valid: 0.7439\n",
      "epoch_loss 0.5189102292060852\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "repeat_time = 10\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "ways = ['width']\n",
    "loss_loses = []\n",
    "loss_accs = []\n",
    "conbimes = ['Mean']\n",
    "print('Different walk time')\n",
    "#walk_timess = [0,4,5,6,7,8,9]\n",
    "for walk_time in tqdm(range(1,8)):\n",
    "    loss_accs = []\n",
    "    acc_accs = []\n",
    "    epoch_times = []\n",
    "    batch_times = []\n",
    "    total_times = []\n",
    "    print('Different seed')\n",
    "    for seed in tqdm(range(repeat_time)):\n",
    "        args = argument()\n",
    "        args.seed = seed\n",
    "        args.time = walk_time\n",
    "        torch.manual_seed(args.seed)\n",
    "        random.seed(args.seed)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        np.random.seed(args.seed)\n",
    "        args.save_path_acc = \"./best_ether/acc/\"\n",
    "        args.save_path_loss = \"./best_ether/loss/\"\n",
    "        args.save_path_acc = args.save_path_acc+ 'ether' + '_dropout='+str(args.dropout)+'_wd='+str(args.weight_decay)+ '_b='+str(args.batch_size)+  '_lr='+str(args.learning_rate)+ '_walk='+ str(args.time)+'_'\n",
    "        args.save_path_loss = args.save_path_loss+ 'ether' + '_dropout='+str(args.dropout)+ '_wd='+str(args.weight_decay)+ '_b='+str(args.batch_size)+  '_lr='+str(args.learning_rate)+ '_walk='+ str(args.time)+'_'\n",
    "        model = Train_Model_Ether(args)\n",
    "        epoch_time, batch_time, total_time = model.fit()\n",
    "        loss_acc,acc_acc = model.evaluation()\n",
    "        epoch_times.append(epoch_time)\n",
    "        total_times.append(total_time)\n",
    "        batch_times.append(batch_time)\n",
    "        loss_accs.append(loss_acc)\n",
    "        acc_accs.append(acc_acc)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    print('#####################################')\n",
    "    print(\"walk_time:\", args.time, 'ways:', args.way, 'conbimeï¼š', args.conbime)\n",
    "    print('batch_times:',sum(batch_times)/repeat_time)\n",
    "    print('epoch_times:',sum(epoch_times)/repeat_time)\n",
    "    print('total_times:',sum(total_times)/repeat_time)\n",
    "    print('loss_accs:',sum(loss_accs)/repeat_time,loss_accs)\n",
    "    print('acc_accs:',sum(acc_accs)/repeat_time,acc_accs)\n",
    "    print(sum(batch_times)/repeat_time, sum(epoch_times)/repeat_time, sum(loss_accs)/repeat_time, sum(acc_accs)/repeat_time)\n",
    "    print('#####################################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
