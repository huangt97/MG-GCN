{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "from train_ether import Train_Model_Ether\n",
    "#from tqdm import tqdm, trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "from model import *\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argument():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'ether'\n",
    "        self.gamma = 1\n",
    "        self.hidden = 128\n",
    "        self.time = 3\n",
    "        self.save_path_acc = \"./best_ether_attn_feat_matrix/acc/\"\n",
    "        self.save_path_loss = \"./best_ether_attn_feat_matrix/loss/\"\n",
    "        self.save_path_both = \"./best_ether_attn_feat_matrix/both/\"\n",
    "        self.walk_path = \"./walks_ether_attention_feat_matrix/\"\n",
    "        self.patience = 30\n",
    "        self.batch_size = 256\n",
    "        self.epochs = 1000\n",
    "        self.learning_rate = 0.001\n",
    "        self.weight_decay = 0\n",
    "        self.num_labels = 41\n",
    "        self.feature_dim = 12\n",
    "        self.walk_times = 10\n",
    "        self.eva_times = 1\n",
    "        self.seed = 2019\n",
    "        self.dropout = 0\n",
    "        self.way = 'both'\n",
    "        self.conbime = 'Lstm'\n",
    "        self.do_walk = False\n",
    "args = argument()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different walk time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a46b63b01c643b08f5e73999ce4aadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different seed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94ead4137994688adb46a2eb9e5f4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features = (1402220, 12) type = <class 'numpy.ndarray'>\n",
      "train_index 572\n",
      "val_index 82\n",
      "test_index 162\n",
      "adj torch.Size([1402220, 1402220])\n",
      "features torch.Size([1402220, 12])\n",
      "train walk\n",
      "load path: ./walks_ether_attention_feat_matrix/train_seed=10_walk=1.mat\n",
      "valid walk\n",
      "load path: ./walks_ether_attention_feat_matrix/valid_seed=10_walk=1.mat\n",
      "self.args.feature_dim = 12\n",
      "cuda ready\n",
      "\n",
      "Training started.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2090142a109437d99adae9852fc16af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train: 19.2517 acc_train: 0.0013 || loss_valid: 35.9555 acc_valid: 0.003\n",
      "epoch 1 loss_train: 13.3576 acc_train: 0.0017 || loss_valid: 30.4646 acc_valid: 0.0045\n",
      "epoch 2 loss_train: 9.8271 acc_train: 0.0023 || loss_valid: 25.8351 acc_valid: 0.0045\n",
      "epoch 3 loss_train: 7.9032 acc_train: 0.0026 || loss_valid: 22.5711 acc_valid: 0.0048\n",
      "epoch 4 loss_train: 6.95 acc_train: 0.0029 || loss_valid: 20.945 acc_valid: 0.0048\n",
      "epoch 5 loss_train: 6.3338 acc_train: 0.0031 || loss_valid: 20.4025 acc_valid: 0.0052\n",
      "epoch 6 loss_train: 5.8017 acc_train: 0.0035 || loss_valid: 20.2084 acc_valid: 0.0062\n",
      "epoch 7 loss_train: 5.3896 acc_train: 0.0036 || loss_valid: 19.7192 acc_valid: 0.0064\n",
      "epoch 8 loss_train: 4.9721 acc_train: 0.0038 || loss_valid: 18.835 acc_valid: 0.0064\n",
      "epoch 9 loss_train: 4.621 acc_train: 0.0038 || loss_valid: 17.9463 acc_valid: 0.0065\n",
      "epoch 10 loss_train: 4.3255 acc_train: 0.0039 || loss_valid: 17.2419 acc_valid: 0.0065\n",
      "epoch 11 loss_train: 4.0814 acc_train: 0.004 || loss_valid: 16.8014 acc_valid: 0.0062\n",
      "epoch 12 loss_train: 3.8947 acc_train: 0.0041 || loss_valid: 16.5601 acc_valid: 0.0064\n",
      "epoch 13 loss_train: 3.7297 acc_train: 0.0041 || loss_valid: 16.3329 acc_valid: 0.007\n",
      "epoch 14 loss_train: 3.5695 acc_train: 0.0043 || loss_valid: 16.006 acc_valid: 0.0073\n",
      "epoch 15 loss_train: 3.4368 acc_train: 0.0044 || loss_valid: 15.7102 acc_valid: 0.0071\n",
      "epoch 16 loss_train: 3.338 acc_train: 0.0044 || loss_valid: 15.5052 acc_valid: 0.0076\n",
      "epoch 17 loss_train: 3.2379 acc_train: 0.0045 || loss_valid: 15.2917 acc_valid: 0.0077\n",
      "epoch 18 loss_train: 3.1505 acc_train: 0.0044 || loss_valid: 15.0203 acc_valid: 0.0079\n",
      "epoch 19 loss_train: 3.0763 acc_train: 0.0045 || loss_valid: 14.7942 acc_valid: 0.008\n",
      "epoch 20 loss_train: 3.0056 acc_train: 0.0045 || loss_valid: 14.6668 acc_valid: 0.0083\n",
      "epoch 21 loss_train: 2.9407 acc_train: 0.0045 || loss_valid: 14.5796 acc_valid: 0.0082\n",
      "epoch 22 loss_train: 2.881 acc_train: 0.0046 || loss_valid: 14.4959 acc_valid: 0.0082\n",
      "epoch 23 loss_train: 2.8258 acc_train: 0.0046 || loss_valid: 14.4189 acc_valid: 0.0083\n",
      "epoch 24 loss_train: 2.7766 acc_train: 0.0046 || loss_valid: 14.3438 acc_valid: 0.0083\n",
      "epoch 25 loss_train: 2.7287 acc_train: 0.0046 || loss_valid: 14.2328 acc_valid: 0.0085\n",
      "epoch 26 loss_train: 2.6833 acc_train: 0.0046 || loss_valid: 14.1019 acc_valid: 0.0083\n",
      "epoch 27 loss_train: 2.6398 acc_train: 0.0046 || loss_valid: 13.9779 acc_valid: 0.0083\n",
      "epoch 28 loss_train: 2.5992 acc_train: 0.0046 || loss_valid: 13.8507 acc_valid: 0.0083\n",
      "epoch 29 loss_train: 2.5607 acc_train: 0.0046 || loss_valid: 13.7151 acc_valid: 0.0083\n",
      "epoch 30 loss_train: 2.5236 acc_train: 0.0046 || loss_valid: 13.5927 acc_valid: 0.0085\n",
      "epoch 31 loss_train: 2.4871 acc_train: 0.0046 || loss_valid: 13.4873 acc_valid: 0.0083\n",
      "epoch 32 loss_train: 2.4512 acc_train: 0.0047 || loss_valid: 13.3863 acc_valid: 0.0083\n",
      "epoch 33 loss_train: 2.4165 acc_train: 0.0047 || loss_valid: 13.2871 acc_valid: 0.0083\n",
      "epoch 34 loss_train: 2.3825 acc_train: 0.0047 || loss_valid: 13.1973 acc_valid: 0.0083\n",
      "epoch 35 loss_train: 2.3489 acc_train: 0.0047 || loss_valid: 13.108 acc_valid: 0.0083\n",
      "epoch 36 loss_train: 2.3161 acc_train: 0.0047 || loss_valid: 13.0111 acc_valid: 0.0083\n",
      "epoch 37 loss_train: 2.2841 acc_train: 0.0047 || loss_valid: 12.9132 acc_valid: 0.0083\n",
      "epoch 38 loss_train: 2.253 acc_train: 0.0047 || loss_valid: 12.8161 acc_valid: 0.0083\n",
      "epoch 39 loss_train: 2.2222 acc_train: 0.0047 || loss_valid: 12.7129 acc_valid: 0.0085\n",
      "epoch 40 loss_train: 2.1916 acc_train: 0.0047 || loss_valid: 12.6125 acc_valid: 0.0086\n",
      "epoch 41 loss_train: 2.1618 acc_train: 0.0047 || loss_valid: 12.5134 acc_valid: 0.0086\n",
      "epoch 42 loss_train: 2.1327 acc_train: 0.0047 || loss_valid: 12.4178 acc_valid: 0.0086\n",
      "epoch 43 loss_train: 2.1051 acc_train: 0.0047 || loss_valid: 12.335 acc_valid: 0.0086\n",
      "epoch 44 loss_train: 2.0769 acc_train: 0.0047 || loss_valid: 12.2366 acc_valid: 0.0086\n",
      "epoch 45 loss_train: 2.049 acc_train: 0.0047 || loss_valid: 12.1279 acc_valid: 0.0086\n",
      "epoch 46 loss_train: 2.0224 acc_train: 0.0047 || loss_valid: 12.0293 acc_valid: 0.0086\n",
      "epoch 47 loss_train: 1.9967 acc_train: 0.0047 || loss_valid: 11.9402 acc_valid: 0.0086\n",
      "epoch 48 loss_train: 1.9713 acc_train: 0.0047 || loss_valid: 11.848 acc_valid: 0.0086\n",
      "epoch 49 loss_train: 1.946 acc_train: 0.0047 || loss_valid: 11.7554 acc_valid: 0.0086\n",
      "epoch 50 loss_train: 1.9213 acc_train: 0.0047 || loss_valid: 11.6663 acc_valid: 0.0088\n",
      "epoch 51 loss_train: 1.8975 acc_train: 0.0047 || loss_valid: 11.5847 acc_valid: 0.0088\n",
      "epoch 52 loss_train: 1.8741 acc_train: 0.0047 || loss_valid: 11.5022 acc_valid: 0.0088\n",
      "epoch 53 loss_train: 1.8508 acc_train: 0.0047 || loss_valid: 11.4224 acc_valid: 0.0089\n",
      "epoch 54 loss_train: 1.8279 acc_train: 0.0047 || loss_valid: 11.3451 acc_valid: 0.0089\n",
      "epoch 55 loss_train: 1.8057 acc_train: 0.0047 || loss_valid: 11.2689 acc_valid: 0.0089\n",
      "epoch 56 loss_train: 1.784 acc_train: 0.0048 || loss_valid: 11.1935 acc_valid: 0.0091\n",
      "epoch 57 loss_train: 1.7627 acc_train: 0.0048 || loss_valid: 11.1213 acc_valid: 0.0091\n",
      "epoch 58 loss_train: 1.7418 acc_train: 0.0048 || loss_valid: 11.0516 acc_valid: 0.0091\n",
      "epoch 59 loss_train: 1.7217 acc_train: 0.0048 || loss_valid: 10.9861 acc_valid: 0.0091\n",
      "epoch 60 loss_train: 1.702 acc_train: 0.0048 || loss_valid: 10.9198 acc_valid: 0.0091\n",
      "epoch 61 loss_train: 1.683 acc_train: 0.0048 || loss_valid: 10.8543 acc_valid: 0.0091\n",
      "epoch 62 loss_train: 1.6647 acc_train: 0.0048 || loss_valid: 10.7893 acc_valid: 0.0091\n",
      "epoch 63 loss_train: 1.6469 acc_train: 0.0048 || loss_valid: 10.7257 acc_valid: 0.0092\n",
      "epoch 64 loss_train: 1.6296 acc_train: 0.0048 || loss_valid: 10.665 acc_valid: 0.0092\n",
      "epoch 65 loss_train: 1.6126 acc_train: 0.0048 || loss_valid: 10.609 acc_valid: 0.0092\n",
      "epoch 66 loss_train: 1.5963 acc_train: 0.0048 || loss_valid: 10.5552 acc_valid: 0.0092\n",
      "epoch 67 loss_train: 1.5803 acc_train: 0.0048 || loss_valid: 10.5047 acc_valid: 0.0092\n",
      "epoch 68 loss_train: 1.5646 acc_train: 0.0048 || loss_valid: 10.4585 acc_valid: 0.0092\n",
      "epoch 69 loss_train: 1.5494 acc_train: 0.0048 || loss_valid: 10.4138 acc_valid: 0.0092\n",
      "epoch 70 loss_train: 1.5347 acc_train: 0.0048 || loss_valid: 10.3647 acc_valid: 0.0092\n",
      "epoch 71 loss_train: 1.5203 acc_train: 0.0048 || loss_valid: 10.314 acc_valid: 0.0092\n",
      "epoch 72 loss_train: 1.5063 acc_train: 0.0049 || loss_valid: 10.2616 acc_valid: 0.0092\n",
      "epoch 73 loss_train: 1.4927 acc_train: 0.0049 || loss_valid: 10.2118 acc_valid: 0.0092\n",
      "epoch 74 loss_train: 1.4795 acc_train: 0.0049 || loss_valid: 10.1651 acc_valid: 0.0092\n",
      "epoch 75 loss_train: 1.4667 acc_train: 0.0049 || loss_valid: 10.1196 acc_valid: 0.0092\n",
      "epoch 76 loss_train: 1.4543 acc_train: 0.0049 || loss_valid: 10.0733 acc_valid: 0.0092\n",
      "epoch 77 loss_train: 1.4423 acc_train: 0.0049 || loss_valid: 10.0264 acc_valid: 0.0092\n",
      "epoch 78 loss_train: 1.4305 acc_train: 0.0049 || loss_valid: 9.983 acc_valid: 0.0092\n",
      "epoch 79 loss_train: 1.4191 acc_train: 0.0049 || loss_valid: 9.9428 acc_valid: 0.0092\n",
      "epoch 80 loss_train: 1.4079 acc_train: 0.0049 || loss_valid: 9.9035 acc_valid: 0.0092\n",
      "epoch 81 loss_train: 1.397 acc_train: 0.0049 || loss_valid: 9.8626 acc_valid: 0.0092\n",
      "epoch 82 loss_train: 1.3864 acc_train: 0.0049 || loss_valid: 9.8227 acc_valid: 0.0094\n",
      "epoch 83 loss_train: 1.3761 acc_train: 0.0049 || loss_valid: 9.7855 acc_valid: 0.0095\n",
      "epoch 84 loss_train: 1.3661 acc_train: 0.0049 || loss_valid: 9.7471 acc_valid: 0.0095\n",
      "epoch 85 loss_train: 1.3562 acc_train: 0.0049 || loss_valid: 9.7107 acc_valid: 0.0095\n",
      "epoch 86 loss_train: 1.3465 acc_train: 0.0049 || loss_valid: 9.6747 acc_valid: 0.0095\n",
      "epoch 87 loss_train: 1.3373 acc_train: 0.0049 || loss_valid: 9.6388 acc_valid: 0.0095\n",
      "epoch 88 loss_train: 1.3281 acc_train: 0.0049 || loss_valid: 9.6071 acc_valid: 0.0095\n",
      "epoch 89 loss_train: 1.3191 acc_train: 0.0049 || loss_valid: 9.5737 acc_valid: 0.0095\n",
      "epoch 90 loss_train: 1.3104 acc_train: 0.0049 || loss_valid: 9.5384 acc_valid: 0.0095\n",
      "epoch 91 loss_train: 1.3018 acc_train: 0.0049 || loss_valid: 9.5037 acc_valid: 0.0097\n",
      "epoch 92 loss_train: 1.2934 acc_train: 0.0049 || loss_valid: 9.4708 acc_valid: 0.0097\n",
      "epoch 93 loss_train: 1.2852 acc_train: 0.0049 || loss_valid: 9.4396 acc_valid: 0.0097\n",
      "epoch 94 loss_train: 1.2772 acc_train: 0.0049 || loss_valid: 9.4097 acc_valid: 0.0097\n",
      "epoch 95 loss_train: 1.2695 acc_train: 0.0049 || loss_valid: 9.3773 acc_valid: 0.0097\n",
      "epoch 96 loss_train: 1.2618 acc_train: 0.0049 || loss_valid: 9.3439 acc_valid: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97 loss_train: 1.2544 acc_train: 0.0049 || loss_valid: 9.3133 acc_valid: 0.0097\n",
      "epoch 98 loss_train: 1.2471 acc_train: 0.0049 || loss_valid: 9.2847 acc_valid: 0.0097\n",
      "epoch 99 loss_train: 1.2399 acc_train: 0.0049 || loss_valid: 9.2566 acc_valid: 0.0097\n",
      "epoch 100 loss_train: 1.2328 acc_train: 0.0049 || loss_valid: 9.2279 acc_valid: 0.0097\n",
      "epoch 101 loss_train: 1.226 acc_train: 0.0049 || loss_valid: 9.2008 acc_valid: 0.0098\n",
      "epoch 102 loss_train: 1.2193 acc_train: 0.0049 || loss_valid: 9.1736 acc_valid: 0.0098\n",
      "epoch 103 loss_train: 1.2126 acc_train: 0.0049 || loss_valid: 9.1453 acc_valid: 0.0098\n",
      "epoch 104 loss_train: 1.2061 acc_train: 0.0049 || loss_valid: 9.1175 acc_valid: 0.0098\n",
      "epoch 105 loss_train: 1.1996 acc_train: 0.0049 || loss_valid: 9.0932 acc_valid: 0.0098\n",
      "epoch 106 loss_train: 1.1932 acc_train: 0.0049 || loss_valid: 9.0722 acc_valid: 0.01\n",
      "epoch 107 loss_train: 1.1871 acc_train: 0.0049 || loss_valid: 9.0503 acc_valid: 0.01\n",
      "epoch 108 loss_train: 1.181 acc_train: 0.0049 || loss_valid: 9.0249 acc_valid: 0.01\n",
      "epoch 109 loss_train: 1.1749 acc_train: 0.0049 || loss_valid: 8.9996 acc_valid: 0.01\n",
      "epoch 110 loss_train: 1.1691 acc_train: 0.0049 || loss_valid: 8.9768 acc_valid: 0.01\n",
      "epoch 111 loss_train: 1.1633 acc_train: 0.0049 || loss_valid: 8.9541 acc_valid: 0.01\n",
      "epoch 112 loss_train: 1.1575 acc_train: 0.0049 || loss_valid: 8.9328 acc_valid: 0.01\n",
      "epoch 113 loss_train: 1.1518 acc_train: 0.0049 || loss_valid: 8.9104 acc_valid: 0.01\n",
      "epoch 114 loss_train: 1.1462 acc_train: 0.0049 || loss_valid: 8.8893 acc_valid: 0.01\n",
      "epoch 115 loss_train: 1.1407 acc_train: 0.0049 || loss_valid: 8.869 acc_valid: 0.01\n",
      "epoch 116 loss_train: 1.1353 acc_train: 0.0049 || loss_valid: 8.8498 acc_valid: 0.01\n",
      "epoch 117 loss_train: 1.13 acc_train: 0.0049 || loss_valid: 8.8311 acc_valid: 0.01\n",
      "epoch 118 loss_train: 1.1247 acc_train: 0.0049 || loss_valid: 8.8121 acc_valid: 0.01\n",
      "epoch 119 loss_train: 1.1194 acc_train: 0.0049 || loss_valid: 8.7919 acc_valid: 0.01\n",
      "epoch 120 loss_train: 1.1143 acc_train: 0.0049 || loss_valid: 8.7716 acc_valid: 0.0101\n",
      "epoch 121 loss_train: 1.1092 acc_train: 0.0049 || loss_valid: 8.7503 acc_valid: 0.0101\n",
      "epoch 122 loss_train: 1.1042 acc_train: 0.0049 || loss_valid: 8.7293 acc_valid: 0.0101\n",
      "epoch 123 loss_train: 1.0992 acc_train: 0.0049 || loss_valid: 8.71 acc_valid: 0.0101\n",
      "epoch 124 loss_train: 1.0943 acc_train: 0.0049 || loss_valid: 8.6904 acc_valid: 0.0101\n",
      "epoch 125 loss_train: 1.0894 acc_train: 0.0049 || loss_valid: 8.6697 acc_valid: 0.0101\n",
      "epoch 126 loss_train: 1.0846 acc_train: 0.0049 || loss_valid: 8.6508 acc_valid: 0.0101\n",
      "epoch 127 loss_train: 1.0799 acc_train: 0.0049 || loss_valid: 8.6327 acc_valid: 0.0101\n",
      "epoch 128 loss_train: 1.0751 acc_train: 0.0049 || loss_valid: 8.6111 acc_valid: 0.0101\n",
      "epoch 129 loss_train: 1.0704 acc_train: 0.0049 || loss_valid: 8.5894 acc_valid: 0.0101\n",
      "epoch 130 loss_train: 1.0658 acc_train: 0.0049 || loss_valid: 8.5732 acc_valid: 0.0101\n",
      "epoch 131 loss_train: 1.0613 acc_train: 0.0049 || loss_valid: 8.557 acc_valid: 0.0101\n",
      "epoch 132 loss_train: 1.0568 acc_train: 0.0049 || loss_valid: 8.536 acc_valid: 0.0101\n",
      "epoch 133 loss_train: 1.0523 acc_train: 0.0049 || loss_valid: 8.516 acc_valid: 0.0101\n",
      "epoch 134 loss_train: 1.0479 acc_train: 0.0049 || loss_valid: 8.4998 acc_valid: 0.0101\n",
      "epoch 135 loss_train: 1.0436 acc_train: 0.0049 || loss_valid: 8.484 acc_valid: 0.0101\n",
      "epoch 136 loss_train: 1.0394 acc_train: 0.0049 || loss_valid: 8.4689 acc_valid: 0.0101\n",
      "epoch 137 loss_train: 1.0352 acc_train: 0.0049 || loss_valid: 8.4526 acc_valid: 0.0101\n",
      "epoch 138 loss_train: 1.031 acc_train: 0.0049 || loss_valid: 8.4342 acc_valid: 0.0101\n",
      "epoch 139 loss_train: 1.0267 acc_train: 0.0049 || loss_valid: 8.4184 acc_valid: 0.0101\n",
      "epoch 140 loss_train: 1.0224 acc_train: 0.0049 || loss_valid: 8.4056 acc_valid: 0.0101\n",
      "epoch 141 loss_train: 1.0181 acc_train: 0.0049 || loss_valid: 8.3921 acc_valid: 0.0101\n",
      "epoch 142 loss_train: 1.0138 acc_train: 0.0049 || loss_valid: 8.3776 acc_valid: 0.0101\n",
      "epoch 143 loss_train: 1.0096 acc_train: 0.0049 || loss_valid: 8.3638 acc_valid: 0.0101\n",
      "epoch 144 loss_train: 1.0055 acc_train: 0.0049 || loss_valid: 8.3489 acc_valid: 0.0101\n",
      "epoch 145 loss_train: 1.0016 acc_train: 0.005 || loss_valid: 8.3298 acc_valid: 0.0101\n",
      "epoch 146 loss_train: 0.9977 acc_train: 0.005 || loss_valid: 8.3117 acc_valid: 0.0101\n",
      "epoch 147 loss_train: 0.9938 acc_train: 0.005 || loss_valid: 8.2974 acc_valid: 0.0101\n",
      "epoch 148 loss_train: 0.9898 acc_train: 0.005 || loss_valid: 8.2829 acc_valid: 0.0101\n",
      "epoch 149 loss_train: 0.986 acc_train: 0.005 || loss_valid: 8.2656 acc_valid: 0.0101\n",
      "epoch 150 loss_train: 0.9823 acc_train: 0.005 || loss_valid: 8.2489 acc_valid: 0.0101\n",
      "epoch 151 loss_train: 0.9786 acc_train: 0.005 || loss_valid: 8.2339 acc_valid: 0.0101\n",
      "epoch 152 loss_train: 0.9748 acc_train: 0.005 || loss_valid: 8.2173 acc_valid: 0.0101\n",
      "epoch 153 loss_train: 0.9711 acc_train: 0.005 || loss_valid: 8.2009 acc_valid: 0.0101\n",
      "epoch 154 loss_train: 0.9674 acc_train: 0.005 || loss_valid: 8.1849 acc_valid: 0.0101\n",
      "epoch 155 loss_train: 0.9638 acc_train: 0.005 || loss_valid: 8.1712 acc_valid: 0.0101\n",
      "epoch 156 loss_train: 0.9602 acc_train: 0.005 || loss_valid: 8.1563 acc_valid: 0.0101\n",
      "epoch 157 loss_train: 0.9566 acc_train: 0.005 || loss_valid: 8.1417 acc_valid: 0.0101\n",
      "epoch 158 loss_train: 0.953 acc_train: 0.005 || loss_valid: 8.1297 acc_valid: 0.0101\n",
      "epoch 159 loss_train: 0.9495 acc_train: 0.005 || loss_valid: 8.1166 acc_valid: 0.0101\n",
      "epoch 160 loss_train: 0.946 acc_train: 0.005 || loss_valid: 8.0979 acc_valid: 0.0101\n",
      "epoch 161 loss_train: 0.9426 acc_train: 0.005 || loss_valid: 8.0798 acc_valid: 0.0101\n",
      "epoch 162 loss_train: 0.9391 acc_train: 0.005 || loss_valid: 8.0736 acc_valid: 0.0101\n",
      "epoch 163 loss_train: 0.9358 acc_train: 0.005 || loss_valid: 8.0661 acc_valid: 0.0101\n",
      "epoch 164 loss_train: 0.9323 acc_train: 0.005 || loss_valid: 8.0605 acc_valid: 0.0101\n",
      "epoch 165 loss_train: 0.93 acc_train: 0.005 || loss_valid: 8.0539 acc_valid: 0.0103\n",
      "epoch 166 loss_train: 0.926 acc_train: 0.005 || loss_valid: 8.0549 acc_valid: 0.0103\n",
      "epoch 167 loss_train: 0.9221 acc_train: 0.005 || loss_valid: 8.0526 acc_valid: 0.0103\n",
      "epoch 168 loss_train: 0.9196 acc_train: 0.005 || loss_valid: 8.0408 acc_valid: 0.0103\n",
      "epoch 169 loss_train: 0.9162 acc_train: 0.005 || loss_valid: 8.032 acc_valid: 0.0103\n",
      "epoch 170 loss_train: 0.9125 acc_train: 0.005 || loss_valid: 8.0283 acc_valid: 0.0104\n",
      "epoch 171 loss_train: 0.9095 acc_train: 0.005 || loss_valid: 8.0192 acc_valid: 0.0104\n",
      "epoch 172 loss_train: 0.9065 acc_train: 0.005 || loss_valid: 8.0122 acc_valid: 0.0104\n",
      "epoch 173 loss_train: 0.9031 acc_train: 0.005 || loss_valid: 8.007 acc_valid: 0.0104\n",
      "epoch 174 loss_train: 0.8998 acc_train: 0.005 || loss_valid: 7.9976 acc_valid: 0.0104\n",
      "epoch 175 loss_train: 0.8969 acc_train: 0.005 || loss_valid: 7.9823 acc_valid: 0.0104\n",
      "epoch 176 loss_train: 0.8936 acc_train: 0.005 || loss_valid: 7.9701 acc_valid: 0.0104\n",
      "epoch 177 loss_train: 0.8905 acc_train: 0.005 || loss_valid: 7.9579 acc_valid: 0.0104\n",
      "epoch 178 loss_train: 0.8875 acc_train: 0.005 || loss_valid: 7.9447 acc_valid: 0.0104\n",
      "epoch 179 loss_train: 0.8845 acc_train: 0.005 || loss_valid: 7.9306 acc_valid: 0.0104\n",
      "epoch 180 loss_train: 0.8814 acc_train: 0.005 || loss_valid: 7.9167 acc_valid: 0.0104\n",
      "epoch 181 loss_train: 0.8784 acc_train: 0.005 || loss_valid: 7.9014 acc_valid: 0.0104\n",
      "epoch 182 loss_train: 0.8755 acc_train: 0.005 || loss_valid: 7.8891 acc_valid: 0.0104\n",
      "epoch 183 loss_train: 0.8725 acc_train: 0.005 || loss_valid: 7.8749 acc_valid: 0.0104\n",
      "epoch 184 loss_train: 0.8694 acc_train: 0.005 || loss_valid: 7.8626 acc_valid: 0.0104\n",
      "epoch 185 loss_train: 0.8666 acc_train: 0.005 || loss_valid: 7.8503 acc_valid: 0.0104\n",
      "epoch 186 loss_train: 0.8638 acc_train: 0.005 || loss_valid: 7.8367 acc_valid: 0.0104\n",
      "epoch 187 loss_train: 0.8608 acc_train: 0.005 || loss_valid: 7.8233 acc_valid: 0.0104\n",
      "epoch 188 loss_train: 0.8579 acc_train: 0.005 || loss_valid: 7.8094 acc_valid: 0.0104\n",
      "epoch 189 loss_train: 0.855 acc_train: 0.005 || loss_valid: 7.7959 acc_valid: 0.0103\n",
      "epoch 190 loss_train: 0.8522 acc_train: 0.005 || loss_valid: 7.7813 acc_valid: 0.0103\n",
      "epoch 191 loss_train: 0.8494 acc_train: 0.005 || loss_valid: 7.7735 acc_valid: 0.0103\n",
      "epoch 192 loss_train: 0.8465 acc_train: 0.005 || loss_valid: 7.7625 acc_valid: 0.0103\n",
      "epoch 193 loss_train: 0.8437 acc_train: 0.005 || loss_valid: 7.7477 acc_valid: 0.0103\n",
      "epoch 194 loss_train: 0.841 acc_train: 0.005 || loss_valid: 7.736 acc_valid: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195 loss_train: 0.8382 acc_train: 0.005 || loss_valid: 7.7257 acc_valid: 0.0103\n",
      "epoch 196 loss_train: 0.8354 acc_train: 0.005 || loss_valid: 7.7145 acc_valid: 0.0103\n",
      "epoch 197 loss_train: 0.8326 acc_train: 0.005 || loss_valid: 7.7029 acc_valid: 0.0103\n",
      "epoch 198 loss_train: 0.8299 acc_train: 0.005 || loss_valid: 7.6911 acc_valid: 0.0103\n",
      "epoch 199 loss_train: 0.8272 acc_train: 0.005 || loss_valid: 7.6772 acc_valid: 0.0103\n",
      "epoch 200 loss_train: 0.8244 acc_train: 0.005 || loss_valid: 7.665 acc_valid: 0.0103\n",
      "epoch 201 loss_train: 0.8218 acc_train: 0.005 || loss_valid: 7.6511 acc_valid: 0.0103\n",
      "epoch 202 loss_train: 0.8191 acc_train: 0.005 || loss_valid: 7.6368 acc_valid: 0.0103\n",
      "epoch 203 loss_train: 0.8164 acc_train: 0.005 || loss_valid: 7.6241 acc_valid: 0.0103\n",
      "epoch 204 loss_train: 0.8137 acc_train: 0.005 || loss_valid: 7.6083 acc_valid: 0.0103\n",
      "epoch 205 loss_train: 0.811 acc_train: 0.005 || loss_valid: 7.5919 acc_valid: 0.0103\n",
      "epoch 206 loss_train: 0.8084 acc_train: 0.005 || loss_valid: 7.576 acc_valid: 0.0103\n",
      "epoch 207 loss_train: 0.8059 acc_train: 0.005 || loss_valid: 7.5571 acc_valid: 0.0103\n",
      "epoch 208 loss_train: 0.8033 acc_train: 0.005 || loss_valid: 7.5363 acc_valid: 0.0103\n",
      "epoch 209 loss_train: 0.8007 acc_train: 0.005 || loss_valid: 7.5198 acc_valid: 0.0103\n",
      "epoch 210 loss_train: 0.7981 acc_train: 0.005 || loss_valid: 7.5062 acc_valid: 0.0103\n",
      "epoch 211 loss_train: 0.7955 acc_train: 0.005 || loss_valid: 7.4922 acc_valid: 0.0103\n",
      "epoch 212 loss_train: 0.793 acc_train: 0.005 || loss_valid: 7.4744 acc_valid: 0.0103\n",
      "epoch 213 loss_train: 0.7905 acc_train: 0.005 || loss_valid: 7.4596 acc_valid: 0.0103\n",
      "epoch 214 loss_train: 0.7879 acc_train: 0.005 || loss_valid: 7.4451 acc_valid: 0.0103\n",
      "epoch 215 loss_train: 0.7854 acc_train: 0.005 || loss_valid: 7.4336 acc_valid: 0.0103\n",
      "epoch 216 loss_train: 0.7828 acc_train: 0.005 || loss_valid: 7.4223 acc_valid: 0.0103\n",
      "epoch 217 loss_train: 0.7804 acc_train: 0.005 || loss_valid: 7.4095 acc_valid: 0.0103\n",
      "epoch 218 loss_train: 0.7779 acc_train: 0.005 || loss_valid: 7.393 acc_valid: 0.0103\n",
      "epoch 219 loss_train: 0.7754 acc_train: 0.005 || loss_valid: 7.3787 acc_valid: 0.0103\n",
      "epoch 220 loss_train: 0.773 acc_train: 0.005 || loss_valid: 7.3691 acc_valid: 0.0101\n",
      "epoch 221 loss_train: 0.7705 acc_train: 0.005 || loss_valid: 7.3574 acc_valid: 0.0101\n",
      "epoch 222 loss_train: 0.7682 acc_train: 0.005 || loss_valid: 7.3461 acc_valid: 0.01\n",
      "epoch 223 loss_train: 0.7658 acc_train: 0.005 || loss_valid: 7.3319 acc_valid: 0.01\n",
      "epoch 224 loss_train: 0.7633 acc_train: 0.005 || loss_valid: 7.3221 acc_valid: 0.01\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f62a80308aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path_loss\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'ether'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_dropout='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_wd='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_b='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m  \u001b[0;34m'_lr='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_epochs='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_walk='\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Model_Ether\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mepoch_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mepoch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zjt/MG-GCN/train_ether.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_feature_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnor_graph_train_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m#                 print(\"epoch_loss\",self.epoch_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zjt/MG-GCN/train_ether.py\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(self, label, batch, feature, graph)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zjt/MG-GCN/train_ether.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(self, label, node, feature, graph)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mloss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mprediction_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_predictive_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zjt/MG-GCN/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node, graph, features)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mA_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zjt/MG-GCN/sub_net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node_x, graph_n_n, features_n_f)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput_x_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_x_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_n_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_f_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_x_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "repeat_time = 10\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "ways = ['width']\n",
    "loss_loses = []\n",
    "loss_accs = []\n",
    "conbimes = ['Mean']\n",
    "print('Different walk time')\n",
    "#walk_timess = [0,4,5,6,7,8,9]\n",
    "for walk_time in tqdm(range(1,10)):\n",
    "    loss_accs = []\n",
    "    acc_accs = []\n",
    "    epoch_times = []\n",
    "    batch_times = []\n",
    "    total_times = []\n",
    "    print('Different seed')\n",
    "    for seed in tqdm(range(10,20)):\n",
    "        args = argument()\n",
    "        args.seed = seed\n",
    "        args.time = walk_time\n",
    "        torch.manual_seed(args.seed)\n",
    "        random.seed(args.seed)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        np.random.seed(args.seed)\n",
    "        args.save_path_acc = \"./best_ether_attn_feat_matrix/acc/\"\n",
    "        args.save_path_loss = \"./best_ether_attn_feat_matrix/loss/\"\n",
    "        args.save_path_acc = args.save_path_acc+ 'ether' + '_dropout='+str(args.dropout)+'_wd='+str(args.weight_decay)+ '_b='+str(args.batch_size)+  '_lr='+str(args.learning_rate)+ '_epochs='+str(args.epochs)+'_walk='+ str(args.time)+'_'\n",
    "        args.save_path_loss = args.save_path_loss+ 'ether' + '_dropout='+str(args.dropout)+ '_wd='+str(args.weight_decay)+ '_b='+str(args.batch_size)+  '_lr='+str(args.learning_rate)+'_epochs='+str(args.epochs)+ '_walk='+ str(args.time)+'_'\n",
    "        model = Train_Model_Ether(args)\n",
    "        epoch_time, batch_time, total_time = model.fit()\n",
    "        loss_acc,acc_acc = model.evaluation()\n",
    "        epoch_times.append(epoch_time)\n",
    "        total_times.append(total_time)\n",
    "        batch_times.append(batch_time)\n",
    "        loss_accs.append(loss_acc)\n",
    "        acc_accs.append(acc_acc)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    print('#####################################')\n",
    "    print(\"walk_time:\", args.time, 'ways:', args.way, 'conbime：', args.conbime)\n",
    "    print('batch_times:',sum(batch_times)/repeat_time)\n",
    "    print('epoch_times:',sum(epoch_times)/repeat_time)\n",
    "    print('total_times:',sum(total_times)/repeat_time)\n",
    "    print('loss_accs:',sum(loss_accs)/repeat_time,loss_accs)\n",
    "    print('acc_accs:',sum(acc_accs)/repeat_time,acc_accs)\n",
    "    print(sum(batch_times)/repeat_time, sum(epoch_times)/repeat_time, sum(loss_accs)/repeat_time, sum(acc_accs)/repeat_time)\n",
    "    print('#####################################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
