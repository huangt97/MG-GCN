{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Attention采样第一阶段做法，直接使用矩阵相乘，不考虑权重及Attention。\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "from train import Train_Model\n",
    "#from tqdm import tqdm, trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "from model import *\n",
    "from utils import *\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_sample_for_ether(walk_times,adj_sparse, train_index, batch_size, save_name, do_walk, features=None):\n",
    "    if do_walk:\n",
    "        nodes_num = len(train_index)\n",
    "        walks = torch.zeros(nodes_num, walk_times+1).long().cuda()\n",
    "        batches = create_batches_forList(train_index, batch_size, True)\n",
    "        i=0\n",
    "        candi_node = 0\n",
    "        indexes = np.arange(0, adj_sparse.shape[0])\n",
    "        for batch in batches:\n",
    "            walks[i*batch_size : i*batch_size + len(batch), 0] = torch.tensor(batch).cuda()\n",
    "            node_adj = adj_sparse[batch.cpu().numpy()]\n",
    "            candi_node = sparse_mx_to_torch_sparse_tensor(node_adj).cuda()\n",
    "            chosen_node = torch.zeros(len(batch), adj_sparse.shape[0]).cuda()\n",
    "            for id in range(len(batch)):\n",
    "                chosen_node[id][batch[id]] = 1.\n",
    "            candi_node = ((- chosen_node + candi_node)> 0.0).float()\n",
    "            for x in range(candi_node.shape[0]):\n",
    "                if candi_node[x].sum() < 0:\n",
    "                    print(\"x = {}\".format(x))\n",
    "                if candi_node[x].sum()==0:\n",
    "                    candi_node[x][batch[x]] = 1.\n",
    "                else:\n",
    "                    x_feat = features[batch[x]]\n",
    "                    x_feat = torch.reshape(x_feat, shape=(x_feat.shape[0], 1))\n",
    "                    batch_x_list = np.array([batch[x]], dtype=np.int32)\n",
    "                    tmp_adj = adj_sparse[batch_x_list]\n",
    "                    tmp_adj = np.array(tmp_adj.toarray()[0], dtype=np.bool)\n",
    "                    tmp_adj = indexes[tmp_adj]\n",
    "                    for y in tmp_adj:\n",
    "                        y_feat = features[y]\n",
    "                        y_feat = torch.reshape(y_feat, shape=(1, y_feat.shape[0]))\n",
    "                        mm_value = torch.mm(y_feat, x_feat)[0][0]\n",
    "                        if mm_value >= 0:\n",
    "                            candi_node[x][y] = mm_value\n",
    "                        else:\n",
    "                            candi_node[x][y] = 0.\n",
    "\n",
    "                            \n",
    "            for walk_id in range(walk_times):\n",
    "                p = candi_node\n",
    "                new_node = torch.multinomial(p,1).squeeze(1)\n",
    "                walks[i*batch_size : i*batch_size + len(batch), walk_id+1] = new_node\n",
    "                for id in range(len(batch)):\n",
    "                    chosen_node[id][new_node[id]] = 1.\n",
    "                candi_node = candi_node - chosen_node + sparse_mx_to_torch_sparse_tensor(adj_sparse[new_node.cpu()]).cuda()\n",
    "                candi_node = (candi_node> 0.0).float()\n",
    "\n",
    "            i+=1\n",
    "        torch.cuda.empty_cache()\n",
    "        result1 = np.array(walks.cpu())\n",
    "        io.savemat(save_name+'.mat',{save_name:result1})\n",
    "        return walks\n",
    "    else:\n",
    "        walks = io.loadmat(save_name+'.mat')\n",
    "        print(\"walks\",walks)\n",
    "        return torch.tensor(walks[save_name]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features = (1402220, 12) type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "sparse_adj, sparse_adj_train,sparse_adj_train_all,features, train_feature,train_feature_all,labels, train_labels, id_train, id_valid, id_test, num_labels = Origin_load_ether_data()\n",
    "sparse_adj.setdiag(1.0) \n",
    "sparse_adj_train.setdiag(1.0) \n",
    "sparse_adj_train_all.setdiag(1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process...train_seed=10_walk=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process...valid_seed=10_walk=1\n",
      "process...test_seed=10_walk=1\n",
      "process...train_seed=11_walk=1\n",
      "process...valid_seed=11_walk=1\n",
      "process...test_seed=11_walk=1\n",
      "process...train_seed=12_walk=1\n",
      "process...valid_seed=12_walk=1\n",
      "process...test_seed=12_walk=1\n",
      "process...train_seed=13_walk=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7892fe4a5eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'seed='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_walk='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'process...'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpre_sample_for_ether\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse_adj_train_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./walks_ether_attention_feat_matrix/train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feature_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'process...'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'valid_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpre_sample_for_ether\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./walks_ether_attention_feat_matrix/valid_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feature_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e6379b264b4d>\u001b[0m in \u001b[0;36mpre_sample_for_ether\u001b[0;34m(walk_times, adj_sparse, train_index, batch_size, save_name, do_walk, features)\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0my_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mmm_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mmm_value\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                             \u001b[0mcandi_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for walk in range(1,20):\n",
    "    for seed in range(10,20):\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        save_name = 'seed='+str(seed)+'_walk='+str(walk)\n",
    "        print('process...'+'train_'+save_name)\n",
    "        pre_sample_for_ether(walk,sparse_adj_train_all, id_train, 32, './walks_ether_attention_feat_matrix/train_'+save_name, True, features=train_feature_all)\n",
    "        print('process...'+'valid_'+save_name)\n",
    "        pre_sample_for_ether(walk,sparse_adj, id_valid, 32, './walks_ether_attention_feat_matrix/valid_'+save_name, True, features=train_feature_all)\n",
    "        print('process...'+'test_'+save_name)\n",
    "        pre_sample_for_ether(walk,sparse_adj, id_test, 32, './walks_ether_attention_feat_matrix/test_'+save_name, True, features=train_feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
